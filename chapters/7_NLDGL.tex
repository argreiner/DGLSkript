\chapter{Nichtlineare gewöhnliche Differentialgleichungen}
Dieser Abschnitt behandelt Beispiele nichtlinearer gewöhnlicher
Differentialgleichungen und deren Lösung mit verschiedenen Zugängen. Zuerst
sollen nichtlineare Systeme erster Ordnung und ersten Grades behandelt werden,
die eine eindeutige Zeitskalentrennung der abhängigen veränderlichen aufweisen
und bei denen es möglich ist, das qualitative Lösungsverhalten durch wenige
instabile Freiheitsgrade auszudrücken ({\red H.Haken, Advanced Synergetics,
Kapitel 7}). Dies führt auf die sogenannten Ordnungsparametergleichungen.
Danach wird auf die numerische Lösung von Differentialgleichungen eingegangen.
\section{Einleitung}
Die Differentialgleichung $\dot q=\alpha q$ ist linear und von erster Ordnung,
während die Gleichung $\ddot q+\omega^2 q=0$ eine lineare Differentialgleichung
2. Ordnung ist, die wir auf ein System von zwei Differentialgleichungen erster
Ordnung und ersten Grades zurückführen können. Wir schreiben
\[
  \begin{matrix}\dot q_1&=q_2\\ \dot q_2&= -\omega^2 q_1 \end{matrix} 
  \quad\text{ oder allgemein }\quad\dot{\mathbf{q}}=L\cdot\mathbf{q}
\]
$L$ bezeichnet hierbei die Koeffizientenmatrix, wir haben es mit einem linearen
System von Differentialgleichungen zu tun.

Jetzt erweitern wir das Konzept auf nichtlineare Differentialgleichungen,
genauer auf ein System nichtlinearer Differentialgleichungen erster Ordnung und
ersten Grades
\begin{align*}
\dot q_1 =& \alpha q_1 + \beta q_1q_2\\
\dot q_1 =&\dots
\end{align*}
Hierbei ist $\beta$ ein Kontrollparameter, der die nichtlineare Kopplung
zwischen den Freiheitsgraden $q_1$ und $q_2$ kontrolliert. Allgemein schreiben
wir so etwas als
\begin{equation}
  \quad\dot{\mathbf{q}}=N(\mathbf{q})
  \label{eq:NLDGLSystem}
\end{equation}
\begin{example}{Nichtlineare Differentialgleichungen}
  \begin{enumerate}
   \item Der van der Pol Oszillator
    \[\ddot x(t)+\mu(x(t)^2-1)\dot x(t)+\omega^2x(t)=0 \]
    den wir wiederum umschreiben zu 1. Ordnung
    \begin{align*}
     \dot y_1=&y_2\\
     \dot y_2=&\mu(1-y_1(t)^2) y_2(t)-\omega^2y_1(t)
    \end{align*}
    Wie sieht das Phasenraumbild aus?
   \item Der Lorenz Attraktor
     \begin{align*}
       \dot x=&\sigma(y-x)\\
       \dot y=&x(\rho-z)-y\\
     \dot z=&xy-\beta z
    \end{align*}
     In Wikipedia steht zu lesen:
     ``Formuliert wurde das System um 1963 von dem Meteorologen Edward N. Lorenz
     (1917–2008), der es als Idealisierung eines hydrodynamischen Systems
     entwickelte. Basierend auf einer Arbeit von Barry Saltzman (1931–2001)
     ging es Lorenz dabei um eine Modellierung der Zustände in der
     Erdatmosphäre zum Zweck einer Langzeitvorhersage. Allerdings betonte
     Lorenz, dass das von ihm entwickelte System allenfalls für sehr begrenzte
     Parameterbereiche von $\sigma$, $\rho$ und $\beta$ realistische
      Resultate liefert.'' (siehe https://de.wikipedia.org/wiki/Lorenz-Attraktor).
   \item Das Volterra-Lotka System der Populationsdynamik
     \begin{align*}
       \dot x=&x-xy\\
       \dot y=&-y+xy
     \end{align*}
  \end{enumerate}
\end{example}
Finden Sie ein Darstellung der Phasenraumbilder der drei Systeme aus obigen
Beispiel!
\Comment{Hier muss was zu Matplotlib kommen!}
\section{Ordnungsparametergleichungen}
\Comment{Das hier ist optional}
Wir betrachten folgendes System gewöhnlicher Differentialgleichungen erster
Ordnung und ersten Grades in den Variablen $u(t)$ und $s(t)$.
\begin{align} 
  \dot{u}&=\alpha u-us
  \label{eq:unstable}\\
  \dot{s}&=-\beta s+u^2
  \label{eq:stable}
\end{align}
Wir nehmen an $\alpha\ge0$ und $\beta>0$. Wir nennen $u$ die instabile und $s$
die stabile Mode - das erklären wir später genauer. Erstmal wollen wir die $s$
durch die $u$ ausdrücken, indem wir so tun, als wären letztere bekannt. Dann
erhalten wir --- Variation der Konstanten anwenden --- folgende Lösung
\begin{equation}
  s(t)=\int\limits_{-\infty}^{t}e^{-\beta(t-\tau)}u(\tau)^2d\tau
  \label{eq:stabelsolu}
\end{equation}
mit der Anfangsbedingung $\lim\limits_{t\rightarrow -\infty}s(t)=0$.
\subsection{Adiabatische Näherung}
Wenn wir (\ref{eq:stabelsolu}) partiell integrieren, erhalten wir
\begin{equation}
  s(t)=\frac{1}{\beta}u^2(t)-\frac{1}{\beta}\int\limits_{-\infty}^{t}e^{-\beta(t-\tau)}
  2(u(\tau)\dot u(\tau))d\tau
  \label{eq:sofueliminated}
\end{equation}
Nehmen wir nun an, dass $u(t)$ sich wenig ändere, so daß $\dot u$ als sehr
klein angenommen werden kann, dann liegt es nahe das Integral in
(\ref{eq:sofueliminated}) zu vernachlässigen. Damit erhalten wir

\begin{equation}
  s(t)=\frac{1}{\beta}u^2(t),
  \label{eq:sapprox}
\end{equation}
was wir auch sofort aus (\ref{eq:stable}) erhalten würden, wenn wir $\dot s=0$
setzten.

Unter welchen Bedingungen sich das  Integral in (\ref{eq:sofueliminated})
vernachlässigen lässt, müssen wir hier noch genauer untersuchen. Wir betrachten
das Maximum des Ausdrucks $Max(u(\tau)\dot u(\tau))=(|u||\dot u|)_{max}$ in
(\ref{eq:sofueliminated}) und schreiben dieses vor das Integral anstatt
$(u(\tau)\dot u(\tau))$ und integrieren. Dann ist unsere Näherung sicherlich
gut, wenn gilt
\begin{equation}
\frac{(|u||\dot u|)_{max}}{\beta^2}<<\frac{|u|^2}{\beta}
  \label{eq:BedElim}
\end{equation}
oder $ |\dot u|_{max}<<\beta|u|$. Dies bedeutet, dass $u$ sich langsam ändert
im Vergleich zur durch die Diffusionskonstante $\beta$ vorgeschriebenen
Änderung. Dies ist die Interpretation der adiabatischen Näherung.
\subsection{Exakte Eliminationsprozedur}
Um die wesentlichen Merkmale diese Prozedur heraus zu arbeiten, wählen wir das
Beispiel $\alpha=0$, so dass (\ref{eq:stable}) ersetzt wird durch $\dot u=-us$.
Wir nutzen jetzt die immer noch exakte Gleichung (\ref{eq:sofueliminated}) und
substituieren darin $\dot u$ mit $-us$ und erhalten
\begin{equation}
  s(t)=\frac{1}{\beta}u^2(t)+\frac{2}{\beta}\int\limits_{-\infty}^{t}e^{-\beta(t-\tau)}
  (u(\tau)^2 s(\tau))d\tau
  \label{eq:soluelimexact}
\end{equation}
(\ref{eq:soluelimexact}) ist eine Integralgleichung für $s(t)$, die wir durch
Iteration lösen. In niedrigster Ordnung drücken wir $s(t)$ durch die Näherung
in (\ref{eq:sapprox}) aus und erhalten
\begin{equation}
  s(t)=\frac{1}{\beta}u^2(t)+\frac{2}{\beta}\int\limits_{-\infty}^{t}e^{-\beta(t-\tau)}
  \frac{1}{\beta}u(\tau)^4d\tau .
  \label{eq:soluelim1st}
\end{equation}
Um den nächsten Iterationsschritt zu erhalten, integrieren wir
(\ref{eq:soluelim1st}) partiell und erhalten 
\begin{equation}
  s(t)=\frac{1}{\beta}u^2(t)+\frac{2}{\beta^3}u(t)^4-
  \frac{8}{\beta^3}\int\limits_{-\infty}^{t}e^{-\beta(t-\tau)}
  (u^3(\tau)\dot u(\tau))d\tau .
  \label{eq:soluelim2nd}
\end{equation}
Unter dem Integral ersetzen wir wieder $\dot u$ wie oben und ersetzen $s$ durch
den zweiten Iterationsschritt (\ref{eq:soluelim2nd}) in dem wir das Integral
vernachlässigt haben und erhalten
\begin{equation}
  s(t)=\frac{1}{\beta}u^2(t)+\frac{2}{\beta^3}u(t)^4-
  \underbrace{
    \frac{8}{\beta^3}\int\limits_{-\infty}^{t}e^{-\beta(t-\tau)}u^4(\tau)
  \left(\frac{1}{\beta}u^2(\tau)+\frac{2}{\beta^3}u(\tau)^4\right)d\tau .
  }_{I}
  \label{eq:soluelim2ndrep}
\end{equation}
Wir behalten vom Integral $I$ aus (\ref{eq:soluelim2ndrep}) zunächst nur die
Terme 6-ter Ordnung
\[ 
  I=\frac{8}{\beta^4}\int\limits_{-\infty}^{t}e^{-\beta(t-\tau)}
  u^6(\tau)d\tau+\text{ h.O.}
\]
Eine erneute partielle Inegration führt auf
\[ 
  s(t)=\frac{1}{\beta}u^2(t)+\frac{2}{\beta^3}u(t)^4+\frac{8}{\beta^5}u(t)^6+\dots
\]
Es ist offensichtlich, dass wir diese Iteration immer weiter betreiben und
somit $s(t)$ als eine Potenzreihe in $u$ ausdrücken können. Wenn $u$ klein
genug ist, erwarten wir, $s$ durch wenige Terme in $u$ annähern zu können.

Dieses Verfahren können wir auch für allgemeinere Gleichungen als $\dot u=-us$,
wie in unserem Beispiel verwendet, anwenden. Für diese Diskussion sei auf die
Literatur verwiesen. Was wir hier festhalten wollen, ist die Tatsache, dass
unter der oben genannten Bedingung (\ref{eq:BedElim}), eine adiabatische
Elimination der stabilen Moden eines Systems durchgeführt werden kann. 

Noch einmal: warum nennen wir $s$ eine stabile Mode? $\beta$ ist sehr groß und
daher relaxiert $s$ sehr schnell auf den stationären Wert, der nun aber durch
$u$ vorgegeben wird. Das ist eine sehr vage Behauptung und diese muss daher
durch eine genaue Untersuchung der Konvergenz der Potenzreihenentwicklung
geklärt werden.
\section{Normalformen}
Anstatt eine Differentialgleichung zu lösen, kann man versuchen, sie in eine möglichst einfache Form über zu führen. D.h. wir suchen eine Variablentransformation, die eine beliebige Differentialgleichung in eine lineare Differentialgleichung überführt. Dies wird nicht immer gelingen.
\begin{example}{Nichlineare Differentiagleichung 1. Ordnung}
  Gegeben sei eine Differentialgleichung der Form
  \begin{equation}\label{eq:1stNL}
  \dot{x}(t)=\lambda x + a_2x^2+a_3x^3+\dots
  \end{equation}
  mit $\lambda\ne 0$. Wir führen folgende Transformation durch
  \begin{equation}\label{eq:Trafo}
  x=y+\alpha_2y^2+\alpha_3y^2+\dots
  \end{equation}
  Wir versuchen die $\alpha_i$ so zu bestimmen, dass die Gleichung für $y$ linear ist. Dazu setzen wir (\ref{eq:Trafo}) in (\ref{eq:1stNL}) ein und erhalten
  \[
  \dot{y}(1+2\alpha_2y+3\alpha_3y^2+\dots)=
  \lambda y+(\lambda\alpha_2+a_2)y^2
  +(\lambda\alpha_3+2a_2\alpha_2+\alpha_3)y^3
  +\dots
  \]
  Wir dividieren durch den Koeffizienten von $\dot{y}$ und entwickeln um $y=0$. Damit erhalten wir
  \[
  \dot{y}=\lambda y+(a_2-\lambda\alpha_2)y^2
  +(\lambda\alpha_3+2\lambda\alpha_2^2
  -2\lambda\alpha_3)y^3
  \]
  Setzen wir nun
  \[
  \alpha_2=\frac{a_2}{\lambda}
  \quad\text{und}\quad
  \alpha_3=\frac{a_2^2}{\lambda^2}+
  \frac{a_3}{2\lambda},
  \]
  dann verschwinden die Terme $y^2$ und $y^3$. D.h. wir haben (\ref{eq:1stNL}) auf eine Normalform dritten Grades gebracht. 
\end{example}

\section{Modellidentifikation}
In diesem Abschnitt wollen wir uns die Fragen stellen, ob es möglich ist aus Signalen eine Differentialgleichung erster Ordnung, oder eine System von Differentialgleichungen erster Ordnung zu rekonstruieren. Was meinen wir damit? 

Gegeben die Signale $x_i(t)$, von denen wir vermuten, dass sie gekoppelt sind. Wie lautet das System von Differentialgleichungen erster Ordnung
\begin{align}
\dot{x}_1(t)&=f_1(x_1,\dots,x_n)\nonumber\\
&\vdots\nonumber\\
\dot{x}_n(t)&=f_n(x_1,\dots,x_n),
\label{eq:sys2reconstruct}
\end{align}
das als Lösung die $x_i(t)$ ergibt? D.h. wir suchen das zu den Signalen $x_i(t)$ gehörige Anfangswertproblem. 


\begin{example}{Rekonstruktion eines Systems von 2 gekoppelten  Differentiagleichung 1. Ordnung}
Wir haben 2 Messsignale $y_1(t)$ und $y_2(t)$ gegeben. Nehmen wir für den Moment mal an, sie lägen analytisch vor, nämlich $y_1(t)=\cos(t)$ und $y_1(t)=\sin(t)$.Dann berechnen wir $\dot y_1(t)=\sin(t)$ und $\dot y_2(t)=-\cos(t)$ Das ergibt das Gleichungssystem
\begin{align*}
\dot{y}_1(t)&=y_2(t)\\
\dot{y}_2(t)&=-y_1(t)
\end{align*}
So einfach haben wir es i.a. nicht. Die allgemeine Vorgehensweise für die Rekonstruktion obigen Systems wäre
\begin{enumerate}
    \item Bilde $\frac{d y_1(t)}{dt}$ und $\frac{d y_2(t)}{dt}$ - meist wird das nur numerisch möglich sein.
    \item Suche zwei Funktionen $f_1(y_1, y_2)$ und $f_2(y_1, y_2)$.
    \item Löse das System 
    \begin{align*}
        \dot{y}_1(t)&=f_1(y_1, y_2)\\
        \dot{y}_2(t)&=f_2(y_1, y_2)
    \end{align*}
\end{enumerate}
Versuchen Sie genau mit dieser Vorgehensweise den harmonischen Oszillator numerisch zu rekonstruieren.
\end{example}
Wie das Beispiel zeigt, liegt die Aufgabe darin geeignete $f_i(y_1,\dots  y_n)$ zu finden. Wenn wir genügend Datenpunkte vorliegen haben, dann gelingt dies eventuell mit der Methode wie sie in Anhang \ref{chap:Fit} beschrieben ist.